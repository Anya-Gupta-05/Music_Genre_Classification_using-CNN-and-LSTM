# ğŸ¶ Music Genre Classification using CNN & LSTM

## ğŸ“Œ Overview
This project performs music genre classification using the **GTZAN dataset**, which includes 10 genres with 100 audio files each. Two separate deep learning models were built to explore different input modalities:

- ğŸ–¼ï¸ **CNN Model** â€“ Trained on spectrogram images generated from audio files.
- ğŸ§ **LSTM Model** â€“ Trained on sequential audio features (MFCCs and more).

---

## ğŸ“ Dataset

- **Name:** GTZAN Music Genre Dataset  
- **Structure:** 10 genres (`rock`, `pop`, `jazz`, `classical`, etc.), 100 audio files per genre  
- **Format:** `.wav` files, each 30 seconds long

---

## ğŸ§  Model Architectures

### ğŸ–¼ï¸ CNN Model (Image-Based)
- Converts audio into **mel spectrogram images**
- Uses a Convolutional Neural Network to learn spatial frequency patterns
- Input: 128Ã—128 grayscale spectrogram images

### ğŸ§ LSTM Model (Audio Feature-Based)
- Extracts **MFCCs**, **chroma features**, **ZCR**, and **RMS energy**
- Uses Long Short-Term Memory (LSTM) networks to capture temporal dependencies
- Input: Time-series audio feature sequences

---

## ğŸ“Š Visuals & Metrics

- Spectrogram image samples
- MFCC feature plots
- Training/validation accuracy & loss graphs
- Confusion matrices for genre prediction

---

## ğŸ› ï¸ Tools & Libraries

- Python
- TensorFlow / Keras
- Librosa (audio processing)
- Matplotlib / Seaborn (visualizations)
- Google Colab (for training with GPU support)
